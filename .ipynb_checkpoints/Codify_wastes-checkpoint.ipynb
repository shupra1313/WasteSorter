{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are developing an artifitial neural network by training our model to be able to classify \n",
    "#between compostable, recyclables and landfill items\n",
    "\n",
    "# we used keras bcos it sis the main library for deep learning in computer vision \n",
    "# and it contains some cool tips and tricks to import images in a most efficient way.\n",
    "# Separate images into 2 seperate folders- test and training each containing 3 different folders for each class label\n",
    "# The business problem here is to classify wastes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subha\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Building the Convolutional Neural Network\n",
    "\n",
    "# import the keras libraries and packages\n",
    "\n",
    "# There are 2 ways of initializing CNN, \n",
    "# either as a sequence of layers or as a layer of graph\n",
    "# Since CNN is a sequence of layers, we use the Sequential package to initialize the NN\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "# The first step in making our NN is adding convolution layer, hence we use the Convolution2D package\n",
    "# Since the pictures are 2 dimensional, we use Convolution2D, for videos its 3D\n",
    "\n",
    "from keras.layers import Convolution2D\n",
    "\n",
    "# The pooling step, will add the pooling layers \n",
    "\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "# In this 3rd step, the flatten package converts all the pooled featured maps created from the convolution \n",
    "# and maxpooling into a large feature vector which the becomes the input for the fully connected layers\n",
    "\n",
    "from keras.layers import Flatten\n",
    "\n",
    "# This package is used to add the fully connected layers in a classic ANN\n",
    "\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Subha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step1 - Convolution\n",
    "\n",
    "# a feature detector/filter of size mentioned below is slided over the entire input image with a stride of 1 and feature maps\n",
    "# are generated correspondigly for each feature\n",
    "# 32-corresponds to the no. of feature detectors/filters and so the feature maps and 3, 3-the size of the feature detectors/filters\n",
    "# input_shape - corresponds to the shape of the input image on which the feature detector is applied\n",
    "# 3 - means 3 channels (RGB) for colored images and 2, for black and white\n",
    "# 64,64 - order for the 2D arrays; more if using GPU - 128,128 or 256,256\n",
    "\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3), activation = 'relu')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2 - Pooling\n",
    "\n",
    "# Maxpooling reduces the size of the feature maps and reduce the number of nodes in the future full connected layers \n",
    "# without losing the performance of the model\n",
    "# Here the feature detector/filter/table (generally 2*2) with a stride of 2 is slided over the feature maps and \n",
    "# the max of each cell is taken and pooled to create a smaller feature map\n",
    "# if maxpooling is applied on a 5*5 feature map, we get a 3*3 pooled feature map (half the original + 1)\n",
    "# if maxpooling is applied on an even feature map, then it would be the original divided by 2\n",
    "# this pooling is done to reduce the size of the number of nodes that we get in the next steps-flatten & full connected step\n",
    "# If maxpooling not applied we get one huge 1 dimensional vectors and too many nodes and \n",
    "# so model will be highly compute intensive\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding a 2nd convolutional layer to increase accuracy\n",
    "\n",
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu')) \n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Subha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                rescale = 1./255,\n",
    "                shear_range = 0.2,\n",
    "                zoom_range = 0.2,\n",
    "                horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Dataset/training_set',\n",
    "                                                target_size=(64, 64),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('Dataset/test_set',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')\n",
    "# Fit the CNN model to the images\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                        steps_per_epoch=2000,\n",
    "                        epochs=20,\n",
    "                        validation_data=test_set,\n",
    "                        validation_steps=800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
